{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a0eb39",
   "metadata": {},
   "source": [
    "# live test \n",
    "\n",
    "encoder : 24 *7 , decoder : 24  \n",
    "실제 일자별 예측을 시각화 및 gif 로 표현하는 노트북  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0a1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package load \n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import gridspec\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error , confusion_matrix\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.metrics.base_metrics import MultiHorizonMetric\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608de28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def images_to_gif(image_files, output_file):\n",
    "    images = [Image.open(image_file) for image_file in image_files]\n",
    "    images[0].save(output_file, save_all=True, append_images=images[1:], optimize=False, duration=700, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e2e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import torch\n",
    "from pytorch_forecasting.metrics.base_metrics import MultiHorizonMetric\n",
    "\n",
    "class CustomLoss(MultiHorizonMetric):\n",
    "    \"\"\"\n",
    "    Quantile loss, i.e. a quantile of ``q=0.5`` will give half of the mean absolute error as it is calculated as\n",
    "\n",
    "    Defined as ``max(q * (y-y_pred), (1-q) * (y_pred-y))``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold: float = 0.5,\n",
    "        quantiles: List[float] = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Quantile loss\n",
    "\n",
    "        Args:\n",
    "            quantiles: quantiles for metric\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        super().__init__(quantiles=quantiles, **kwargs)\n",
    "\n",
    "    def loss(self, y_pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        # calculate quantile loss\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1) * (self.calculate_f1_loss(target , - y_pred[..., i])))\n",
    "        losses = 2 * torch.cat(losses, dim=2)\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def calculate_f1_loss(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        y_true_binary = (y_true > self.threshold).float()\n",
    "        #y_pred = self.to_prediction(y_pred)\n",
    "        y_pred_binary = (y_pred > self.threshold).float()\n",
    "\n",
    "        tp = torch.sum(y_true_binary * y_pred_binary, dim=0)\n",
    "        fp = torch.sum((1 - y_true_binary) * y_pred_binary, dim=0)\n",
    "        fn = torch.sum(y_true_binary * (1 - y_pred_binary), dim=0)\n",
    "\n",
    "        epsilon = 1e-7  # to prevent division by zero\n",
    "        precision = tp / (tp + fp + epsilon)\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "        return 1 - f1.mean()  # return 1 minus mean f1 score to make it a loss (lower is better)\n",
    "\n",
    "\n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert network prediction into a point prediction.\n",
    "\n",
    "        Args:\n",
    "            y_pred: prediction output of network\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: point prediction\n",
    "        \"\"\"\n",
    "        if y_pred.ndim == 3:\n",
    "            idx = self.quantiles.index(0.5)\n",
    "            y_pred = y_pred[..., idx]\n",
    "        return y_pred\n",
    "\n",
    "    def to_quantiles(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert network prediction into a quantile prediction.\n",
    "\n",
    "        Args:\n",
    "            y_pred: prediction output of network\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: prediction quantiles\n",
    "        \"\"\"\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed78a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_type = 'ControlGroup'\n",
    "\n",
    "# transform_type = lossGroup 으로 해서 코드 실행\n",
    "\n",
    "\n",
    "quantiles = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "alpha_start = 0.7\n",
    "\n",
    "filter5 = np.array([2, 1, 0]) / 3\n",
    "filter = np.exp(-np.arange(len(filter5)))\n",
    "\n",
    "def triangle_conv(time_series):\n",
    "    global filter\n",
    "    size = len(filter)\n",
    "    shift = size // 2\n",
    "    conv_result = np.convolve(time_series, filter, mode='same')\n",
    "    conv_result = np.roll(conv_result, shift)\n",
    "    return conv_result\n",
    "\n",
    "def inv_conv(time_series):\n",
    "    return time_series\n",
    "\n",
    "\n",
    "transformation_dict = {\n",
    "    'forward': triangle_conv,\n",
    "    'reverse': inv_conv, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ac1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../DataProcessing/train_data/Long Beach_5.csv')\n",
    "train_data = train_data[-744*15:]\n",
    "x_range = train_data.OccTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a4ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './sparity_test_configs'\n",
    "trail_num = 0\n",
    "configs = natsorted(os.listdir(directory_path))\n",
    "filtered_list = [file for file in configs if not file.startswith('.ipy')]\n",
    "file_path = os.path.join(directory_path , filtered_list[trail_num])\n",
    "with open(file_path, 'r') as json_file:\n",
    "    config_p = json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7764878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lightning_logs/ControlGroup/lightning_logs/version_12/checkpoints/epoch=9-step=22170.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_p['conv_none_model_ckpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0640342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_datas = natsorted(os.listdir('../../DataProcessing/train_data/Long Beach_5_val'))\n",
    "val_datas = natsorted(os.listdir('../../DataProcessing/train_data/Long Beach_5_val'), reverse=True)\n",
    "    \n",
    "    \n",
    "max_prediction_length = 24\n",
    "max_encoder_length = 24*7\n",
    "data = pd.read_csv('../../DataProcessing/train_data/Long Beach_5_split.csv')\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Accient\",\n",
    "    group_ids=[\"GeoHash\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=data.columns[4: -2].tolist(),\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"GeoHash\"], transformation=None\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 256  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "#val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb4aa7",
   "metadata": {},
   "source": [
    "### conv_none_live_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeef504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "date processing:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "load_tft = TemporalFusionTransformer.load_from_checkpoint(config_p['conv_none_model_ckpt'])\n",
    "predictions_list = []\n",
    "real_list = []\n",
    "figs_dict = defaultdict(lambda: make_subplots(specs=[[{\"secondary_y\": True}]]))  # dict of figures, one per GeoHash\n",
    "steps_dict = defaultdict(list)  # dict of steps, one list per GeoHash\n",
    "\n",
    "for val_idx , val_data_list in enumerate(tqdm_notebook(val_datas , leave=False , desc = 'date processing')):\n",
    "    val_data_path = os.path.join('../../DataProcessing/train_data/Long Beach_5_val' , val_data_list)\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, val_data, predict=True, stop_randomization=True)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    predictions = load_tft.predict(val_dataloader, mode=\"raw\" , return_x=True , return_index=True ,  trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "    raw_predictions = predictions[0]\n",
    "    x = predictions[1]\n",
    "    idx_df = predictions[2]\n",
    "\n",
    "    for idx in range(raw_predictions['prediction'].shape[0]):\n",
    "        group = idx_df.loc[idx, 'GeoHash']\n",
    "        fig_plolty = figs_dict[group]  # get or create figure for this GeoHash\n",
    "        steps = steps_dict[group]  # get or create steps list for this GeoHash\n",
    "\n",
    "        y_pred = raw_predictions['prediction'][idx].unsqueeze(0)  # (sequence_length, num_quantiles) -> (1, sequence_length, num_quantiles)\n",
    "        y_true = x['decoder_target'][idx].unsqueeze(0)  # (sequence_length,) -> (1, sequence_length, 1)\n",
    "\n",
    "        loss_fn = QuantileLoss()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "        for quantile_idx in range(len(quantiles)):\n",
    "            quantile = quantiles[quantile_idx]  # Access the quantile value from the list\n",
    "            alpha_color = alpha_start - quantile_idx / len(quantiles) * 0.7  # Calculate alpha value based on quantile index\n",
    "            fillcolor = f'rgba(0, 0, 255, {alpha_color})'  # Set the fill color with adjusted alpha value\n",
    "\n",
    "            fig_plolty.add_trace(go.Scatter(\n",
    "                x=np.arange(0,24),\n",
    "                y=raw_predictions['prediction'][idx, :, quantile_idx],\n",
    "                mode='lines',\n",
    "                name=f'Quantile {quantile_idx}',\n",
    "                line=dict(color='blue'),\n",
    "                fill='tozeroy',  # Fill the area below the line\n",
    "                fillcolor='rgba(0, 0, 255, 0.7)',  # Set the fill color with adjusted alpha value\n",
    "            ), row=1, col=1)\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(0,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        actual_trace = go.Scatter(\n",
    "            x=np.arange(-168+24,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        )\n",
    "        fig_plolty.add_trace(actual_trace)\n",
    "\n",
    "        attention_data = raw_predictions['encoder_attention'][idx].mean(dim=(0, 1))\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(-168+24, 24),\n",
    "            y=attention_data,\n",
    "            mode='lines',\n",
    "            name='Encoder Attention',\n",
    "            line=dict(color='rgba(128, 128, 128, 0.6)')  # Set the color to gray with opacity 0.6\n",
    "        ), secondary_y=True, row=1, col=1)\n",
    "\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            args=[\n",
    "                {\"visible\": [j//10 == val_idx for j in range(len(val_datas)*11)]},\n",
    "                {\"title\": f\"Plot Prediction (Loss: {loss.item():.8f}) {group} date {val_idx + 1}\"},\n",
    "            ],\n",
    "        )\n",
    "        steps.append(step)\n",
    "\n",
    "for group in figs_dict.keys():\n",
    "    fig_plolty = figs_dict[group]\n",
    "    steps = steps_dict[group]\n",
    "    fig_plolty.update_layout(\n",
    "        sliders=[dict(\n",
    "            steps=steps,\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    filename = f\"./{transform_type}_result/live_test/conv_none/{group}.html\"  # modify this to specify your preferred filename and path\n",
    "    dir_path = os.path.dirname(filename)  # Get the directory path\n",
    "    os.makedirs(dir_path, exist_ok=True)  # Create the directory if it does not exist\n",
    "    pyo.plot(fig_plolty, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8032c52",
   "metadata": {},
   "source": [
    "### concateloss result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bb5a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "date processing:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "load_tft = TemporalFusionTransformer.load_from_checkpoint(config_p['concateloss_model_ckpt'])\n",
    "predictions_list = []\n",
    "real_list = []\n",
    "figs_dict = defaultdict(lambda: make_subplots(specs=[[{\"secondary_y\": True}]]))  # dict of figures, one per GeoHash\n",
    "steps_dict = defaultdict(list)  # dict of steps, one list per GeoHash\n",
    "\n",
    "for val_idx , val_data_list in enumerate(tqdm_notebook(val_datas , leave=False , desc = 'date processing')):\n",
    "    val_data_path = os.path.join('../../DataProcessing/train_data/Long Beach_5_val' , val_data_list)\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, val_data, predict=True, stop_randomization=True)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    predictions = load_tft.predict(val_dataloader, mode=\"raw\" , return_x=True , return_index=True ,  trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "    raw_predictions = predictions[0]\n",
    "    x = predictions[1]\n",
    "    idx_df = predictions[2]\n",
    "\n",
    "    for idx in range(raw_predictions['prediction'].shape[0]):\n",
    "        group = idx_df.loc[idx, 'GeoHash']\n",
    "        fig_plolty = figs_dict[group]  # get or create figure for this GeoHash\n",
    "        steps = steps_dict[group]  # get or create steps list for this GeoHash\n",
    "\n",
    "        y_pred = raw_predictions['prediction'][idx].unsqueeze(0)  # (sequence_length, num_quantiles) -> (1, sequence_length, num_quantiles)\n",
    "        y_true = x['decoder_target'][idx].unsqueeze(0)  # (sequence_length,) -> (1, sequence_length, 1)\n",
    "\n",
    "        loss_fn = QuantileLoss()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "        for quantile_idx in range(len(quantiles)):\n",
    "            quantile = quantiles[quantile_idx]  # Access the quantile value from the list\n",
    "            alpha_color = alpha_start - quantile_idx / len(quantiles) * 0.7  # Calculate alpha value based on quantile index\n",
    "            fillcolor = f'rgba(0, 0, 255, {alpha_color})'  # Set the fill color with adjusted alpha value\n",
    "\n",
    "            fig_plolty.add_trace(go.Scatter(\n",
    "                x=np.arange(0,24),\n",
    "                y=raw_predictions['prediction'][idx, :, quantile_idx],\n",
    "                mode='lines',\n",
    "                name=f'Quantile {quantile_idx}',\n",
    "                line=dict(color='blue'),\n",
    "                fill='tozeroy',  # Fill the area below the line\n",
    "                fillcolor='rgba(0, 0, 255, 0.7)',  # Set the fill color with adjusted alpha value\n",
    "            ), row=1, col=1)\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(0,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        actual_trace = go.Scatter(\n",
    "            x=np.arange(-168+24,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        )\n",
    "        fig_plolty.add_trace(actual_trace)\n",
    "\n",
    "        attention_data = raw_predictions['encoder_attention'][idx].mean(dim=(0, 1))\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(-168+24, 24),\n",
    "            y=attention_data,\n",
    "            mode='lines',\n",
    "            name='Encoder Attention',\n",
    "            line=dict(color='rgba(128, 128, 128, 0.6)')  # Set the color to gray with opacity 0.6\n",
    "        ), secondary_y=True, row=1, col=1)\n",
    "\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            args=[\n",
    "                {\"visible\": [j//10 == val_idx for j in range(len(val_datas)*11)]},\n",
    "                {\"title\": f\"Plot Prediction (Loss: {loss.item():.8f}) {group} date {val_idx + 1}\"},\n",
    "            ],\n",
    "        )\n",
    "        steps.append(step)\n",
    "\n",
    "for group in figs_dict.keys():\n",
    "    fig_plolty = figs_dict[group]\n",
    "    steps = steps_dict[group]\n",
    "    fig_plolty.update_layout(\n",
    "        sliders=[dict(\n",
    "            steps=steps,\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    filename = f\"./{transform_type}_result/live_test/concateloss/{group}.html\"  # modify this to specify your preferred filename and path\n",
    "    dir_path = os.path.dirname(filename)  # Get the directory path\n",
    "    os.makedirs(dir_path, exist_ok=True)  # Create the directory if it does not exist\n",
    "    pyo.plot(fig_plolty, filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d31a03",
   "metadata": {},
   "source": [
    "### nei result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02df980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash\n",
    "import math\n",
    "\n",
    "def l2_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "    \n",
    "    d_lat = lat2_rad - lat1_rad\n",
    "    d_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    distance = math.sqrt(d_lat**2 + d_lon**2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def get_nei_geohash_max(geohashes):\n",
    "    nei_ghs = geohash.neighbors(geohashes)\n",
    "    lat, lon = geohash.decode(geohashes)\n",
    "\n",
    "    decoded_list = [geohash.decode(gh) for gh in nei_ghs]\n",
    "    l2_distances = [l2_distance(lat, lon, lat_decoded, lon_decoded) for lat_decoded, lon_decoded in decoded_list]\n",
    "    max_distance = max(l2_distances)\n",
    "\n",
    "    # Get the indices of the top 4 geohashes with the largest L2 distances\n",
    "    top_indices = sorted(range(len(l2_distances)), key=lambda i: l2_distances[i], reverse=True)[:4]\n",
    "    geohashes_with_max_distance = [nei_ghs[i] for i in top_indices]\n",
    "\n",
    "    return geohashes_with_max_distance\n",
    "\n",
    "def get_nei_geohash_min(geohashes):\n",
    "    nei_ghs = geohash.neighbors(geohashes)\n",
    "    lat, lon = geohash.decode(geohashes)\n",
    "\n",
    "    decoded_list = [geohash.decode(gh) for gh in nei_ghs]\n",
    "    l2_distances = [l2_distance(lat, lon, lat_decoded, lon_decoded) for lat_decoded, lon_decoded in decoded_list]\n",
    "    min_distance = min(l2_distances)\n",
    "\n",
    "    # Get the indices of the top 4 geohashes with the smallest L2 distances\n",
    "    top_indices = sorted(range(len(l2_distances)), key=lambda i: l2_distances[i])[:4]\n",
    "    geohashes_with_min_distance = [nei_ghs[i] for i in top_indices]\n",
    "\n",
    "    return geohashes_with_min_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a6112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../DataProcessing/train_data/Long Beach_5_split.csv')\n",
    "\n",
    "for ghs in data['GeoHash'].unique():\n",
    "    gh_data = data[data['GeoHash'] == ghs]\n",
    "\n",
    "    # Get max data for each neighboring geohash\n",
    "    max_data = []\n",
    "    for inner_nei in get_nei_geohash_max(ghs):\n",
    "        inner_nei_data = data[data['GeoHash'] == inner_nei]['Accient'].to_list()\n",
    "        if inner_nei_data:  # Check if the list is not empty\n",
    "            max_data.append([val * 1.0 for val in inner_nei_data])\n",
    "\n",
    "    # Get min data for each neighboring geohash\n",
    "    min_data = []\n",
    "    for inner_nei in get_nei_geohash_min(ghs):\n",
    "        inner_nei_data = data[data['GeoHash'] == inner_nei]['Accient'].to_list()\n",
    "        if inner_nei_data:  # Check if the list is not empty\n",
    "            min_data.append([val * 1.0 for val in inner_nei_data])\n",
    "\n",
    "    # Calculate the sum of max_data and min_data\n",
    "    sum_max_data = np.sum(max_data, axis=0) if max_data else []\n",
    "    sum_min_data = np.sum(min_data, axis=0) if min_data else []\n",
    "    gh_data['nei'] = gh_data['Accient'] + sum_max_data + sum_min_data\n",
    "    data.loc[gh_data.index , \"nei\"] = gh_data['nei'] + sum_max_data + sum_min_data\n",
    "data['nei'].fillna(0, inplace=True)\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Accient\",\n",
    "    group_ids=[\"GeoHash\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=data.columns[4: -3].tolist() + ['nei'],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"GeoHash\"], transformation=None\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size=256\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d346ebff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "date processing:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "load_tft = TemporalFusionTransformer.load_from_checkpoint(config_p['nei_model_ckpt'])\n",
    "predictions_list = []\n",
    "real_list = []\n",
    "figs_dict = defaultdict(lambda: make_subplots(specs=[[{\"secondary_y\": True}]]))  # dict of figures, one per GeoHash\n",
    "steps_dict = defaultdict(list)  # dict of steps, one list per GeoHash\n",
    "\n",
    "for val_idx , val_data_list in enumerate(tqdm_notebook(val_datas , leave=False , desc = 'date processing')):\n",
    "    val_data_path = os.path.join('../../DataProcessing/train_data/Long Beach_5_val' , val_data_list)\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    \n",
    "    for ghs in val_data['GeoHash'].unique():\n",
    "        gh_data = val_data[val_data['GeoHash'] == ghs]\n",
    "\n",
    "        # Get max data for each neighboring geohash\n",
    "        max_data = []\n",
    "        for inner_nei in get_nei_geohash_max(ghs):\n",
    "            inner_nei_data = val_data[val_data['GeoHash'] == inner_nei]['Accient'].to_list()\n",
    "            if inner_nei_data:  # Check if the list is not empty\n",
    "                max_data.append([val * 1.0 for val in inner_nei_data])\n",
    "\n",
    "        # Get min data for each neighboring geohash\n",
    "        min_data = []\n",
    "        for inner_nei in get_nei_geohash_min(ghs):\n",
    "            inner_nei_data = val_data[val_data['GeoHash'] == inner_nei]['Accient'].to_list()\n",
    "            if inner_nei_data:  # Check if the list is not empty\n",
    "                min_data.append([val * 1.0 for val in inner_nei_data])\n",
    "\n",
    "        # Calculate the sum of max_data and min_data\n",
    "        sum_max_data = np.sum(max_data, axis=0) if max_data else []\n",
    "        sum_min_data = np.sum(min_data, axis=0) if min_data else []\n",
    "        gh_data['nei'] = gh_data['Accient'] + sum_max_data + sum_min_data\n",
    "        val_data.loc[gh_data.index , \"nei\"] = gh_data['nei'] + sum_max_data + sum_min_data\n",
    "    val_data['nei'].fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, val_data, predict=True, stop_randomization=True)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    predictions = load_tft.predict(val_dataloader, mode=\"raw\" , return_x=True , return_index=True ,  trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "    raw_predictions = predictions[0]\n",
    "    x = predictions[1]\n",
    "    idx_df = predictions[2]\n",
    "\n",
    "    for idx in range(raw_predictions['prediction'].shape[0]):\n",
    "        group = idx_df.loc[idx, 'GeoHash']\n",
    "        fig_plolty = figs_dict[group]  # get or create figure for this GeoHash\n",
    "        steps = steps_dict[group]  # get or create steps list for this GeoHash\n",
    "\n",
    "        y_pred = raw_predictions['prediction'][idx].unsqueeze(0)  # (sequence_length, num_quantiles) -> (1, sequence_length, num_quantiles)\n",
    "        y_true = x['decoder_target'][idx].unsqueeze(0)  # (sequence_length,) -> (1, sequence_length, 1)\n",
    "\n",
    "        loss_fn = QuantileLoss()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "        for quantile_idx in range(len(quantiles)):\n",
    "            quantile = quantiles[quantile_idx]  # Access the quantile value from the list\n",
    "            alpha_color = alpha_start - quantile_idx / len(quantiles) * 0.7  # Calculate alpha value based on quantile index\n",
    "            fillcolor = f'rgba(0, 0, 255, {alpha_color})'  # Set the fill color with adjusted alpha value\n",
    "\n",
    "            fig_plolty.add_trace(go.Scatter(\n",
    "                x=np.arange(0,24),\n",
    "                y=raw_predictions['prediction'][idx, :, quantile_idx],\n",
    "                mode='lines',\n",
    "                name=f'Quantile {quantile_idx}',\n",
    "                line=dict(color='blue'),\n",
    "                fill='tozeroy',  # Fill the area below the line\n",
    "                fillcolor='rgba(0, 0, 255, 0.7)',  # Set the fill color with adjusted alpha value\n",
    "            ), row=1, col=1)\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(0,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        actual_trace = go.Scatter(\n",
    "            x=np.arange(-168+24,24),\n",
    "            y=x['encoder_target'][idx],\n",
    "            mode='lines',\n",
    "            name='Encoder Real',\n",
    "            line=dict(color='black')\n",
    "        )\n",
    "        fig_plolty.add_trace(actual_trace)\n",
    "\n",
    "        attention_data = raw_predictions['encoder_attention'][idx].mean(dim=(0, 1))\n",
    "\n",
    "        fig_plolty.add_trace(go.Scatter(\n",
    "            x=np.arange(-168+24, 24),\n",
    "            y=attention_data,\n",
    "            mode='lines',\n",
    "            name='Encoder Attention',\n",
    "            line=dict(color='rgba(128, 128, 128, 0.6)')  # Set the color to gray with opacity 0.6\n",
    "        ), secondary_y=True, row=1, col=1)\n",
    "\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            args=[\n",
    "                {\"visible\": [j//10 == val_idx for j in range(len(val_datas)*11)]},\n",
    "                {\"title\": f\"Plot Prediction (Loss: {loss.item():.8f}) {group} date {val_idx + 1}\"},\n",
    "            ],\n",
    "        )\n",
    "        steps.append(step)\n",
    "\n",
    "for group in figs_dict.keys():\n",
    "    fig_plolty = figs_dict[group]\n",
    "    steps = steps_dict[group]\n",
    "    fig_plolty.update_layout(\n",
    "        sliders=[dict(\n",
    "            steps=steps,\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    filename = f\"./{transform_type}_result/live_test/nei/{group}.html\"  # modify this to specify your preferred filename and path\n",
    "    dir_path = os.path.dirname(filename)  # Get the directory path\n",
    "    os.makedirs(dir_path, exist_ok=True)  # Create the directory if it does not exist\n",
    "    pyo.plot(fig_plolty, filename=filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
