{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d7b00d",
   "metadata": {},
   "source": [
    "# Sparsity loss\n",
    "\n",
    "pytorch-forecasting 패키지에서 제공해주는 quantile loss를 변경해서 confusion matrix의 비율에 따라서 다르게 적용되도록 변경\n",
    "\n",
    "> QuantileLoss : https://pytorch-forecasting.readthedocs.io/en/stable/_modules/pytorch_forecasting/metrics/quantile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9710d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nplab/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 원본 quantile loss\n",
    "\"\"\"Quantile metrics for forecasting multiple quantiles per time step.\"\"\"\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting.metrics.base_metrics import MultiHorizonMetric\n",
    "\n",
    "\n",
    "class QuantileLoss(MultiHorizonMetric):\n",
    "    \"\"\"\n",
    "    Quantile loss, i.e. a quantile of ``q=0.5`` will give half of the mean absolute error as it is calculated as\n",
    "\n",
    "    Defined as ``max(q * (y-y_pred), (1-q) * (y_pred-y))``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        quantiles: List[float] = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Quantile loss\n",
    "\n",
    "        Args:\n",
    "            quantiles: quantiles for metric\n",
    "        \"\"\"\n",
    "        super().__init__(quantiles=quantiles, **kwargs)\n",
    "\n",
    "    def loss(self, y_pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        # calculate quantile loss\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1))\n",
    "        losses = 2 * torch.cat(losses, dim=2)\n",
    "\n",
    "        return losses\n",
    "\n",
    "\n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert network prediction into a point prediction.\n",
    "\n",
    "        Args:\n",
    "            y_pred: prediction output of network\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: point prediction\n",
    "        \"\"\"\n",
    "        if y_pred.ndim == 3:\n",
    "            idx = self.quantiles.index(0.5)\n",
    "            y_pred = y_pred[..., idx]\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def to_quantiles(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert network prediction into a quantile prediction.\n",
    "\n",
    "        Args:\n",
    "            y_pred: prediction output of network\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: prediction quantiles\n",
    "        \"\"\"\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75857dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(MultiHorizonMetric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        quantiles: List[float] = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(quantiles=quantiles, **kwargs)\n",
    "\n",
    "    def loss(self, y_pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1))\n",
    "        losses = 2 * torch.cat(losses, dim=2)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        if y_pred.ndim == 3:\n",
    "            idx = self.quantiles.index(0.5)\n",
    "            y_pred = y_pred[..., idx]\n",
    "        return y_pred\n",
    "\n",
    "    def to_quantiles(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d73e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "real_t = torch.zeros(4, 24)\n",
    "pred_t = torch.zeros(4, 24, 7)\n",
    "\n",
    "real_t[0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2830fd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 24, 7]), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = QuantileLoss()\n",
    "losses.loss(pred_t,real_t).shape , losses.loss(pred_t,real_t).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f9eb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "931ec277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(MultiHorizonMetric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        quantiles: List[float] = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(quantiles=quantiles, **kwargs)\n",
    "\n",
    "    def loss(self, y_pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1))\n",
    "        losses = 2 * torch.cat(losses, dim=2)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        if y_pred.ndim == 3:\n",
    "            idx = self.quantiles.index(0.5)\n",
    "            y_pred = y_pred[..., idx]\n",
    "        return y_pred\n",
    "\n",
    "    def to_quantiles(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc3ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>error</th>\n",
       "      <th>quantile_loss_0.02</th>\n",
       "      <th>quantile_loss_0.1</th>\n",
       "      <th>quantile_loss_0.25</th>\n",
       "      <th>quantile_loss_0.5</th>\n",
       "      <th>quantile_loss_0.75</th>\n",
       "      <th>quantile_loss_0.9</th>\n",
       "      <th>quantile_loss_0.98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FP</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.350</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   real  pred confusion_matrix  error  quantile_loss_0.02  quantile_loss_0.1  \\\n",
       "0     0   0.0               TN   0.00               0.000              0.000   \n",
       "1     0   0.5                    0.75               0.735              0.675   \n",
       "2     0   1.0               FP   1.50               1.470              1.350   \n",
       "3     1   0.0               FN   1.00               0.020              0.100   \n",
       "4     1   0.5                    0.25               0.005              0.025   \n",
       "5     1   1.0               TP   0.50               0.490              0.450   \n",
       "\n",
       "   quantile_loss_0.25  quantile_loss_0.5  quantile_loss_0.75  \\\n",
       "0              0.0000              0.000              0.0000   \n",
       "1              0.5625              0.375              0.1875   \n",
       "2              1.1250              0.750              0.3750   \n",
       "3              0.2500              0.500              0.7500   \n",
       "4              0.0625              0.125              0.1875   \n",
       "5              0.3750              0.250              0.1250   \n",
       "\n",
       "   quantile_loss_0.9  quantile_loss_0.98  \n",
       "0              0.000               0.000  \n",
       "1              0.075               0.015  \n",
       "2              0.150               0.030  \n",
       "3              0.900               0.980  \n",
       "4              0.225               0.245  \n",
       "5              0.050               0.010  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def quantile_loss(tau, real, pred):\n",
    "    error = real - 1.5 * pred\n",
    "    return tau * max(error, 0) + (1 - tau) * max(-error, 0)\n",
    "\n",
    "data_points = [\n",
    "    {\"real\": 0, \"pred\": 0, \"confusion_matrix\": \"TN\", \"error\": 0},\n",
    "    {\"real\": 0, \"pred\": 0.5, \"confusion_matrix\": \"\", \"error\": 0.75},\n",
    "    {\"real\": 0, \"pred\": 1, \"confusion_matrix\": \"FP\", \"error\": 1.5},\n",
    "    {\"real\": 1, \"pred\": 0, \"confusion_matrix\": \"FN\", \"error\": 1},\n",
    "    {\"real\": 1, \"pred\": 0.5, \"confusion_matrix\": \"\", \"error\": 0.25},\n",
    "    {\"real\": 1, \"pred\": 1, \"confusion_matrix\": \"TP\", \"error\": 0.5},\n",
    "]\n",
    "\n",
    "taus = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "\n",
    "for tau in taus:\n",
    "    for data_point in data_points:\n",
    "        real = data_point['real']\n",
    "        pred = data_point['pred']\n",
    "        data_point[f'quantile_loss_{tau}'] = quantile_loss(tau, real, pred)\n",
    "\n",
    "df = pd.DataFrame(data_points)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7faca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(MultiHorizonMetric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        quantiles: List[float] = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(quantiles=quantiles, **kwargs)\n",
    "\n",
    "    def loss(self, y_pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = target - 1.5 * y_pred[..., i]\n",
    "            losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(-1))\n",
    "        losses = 2 * torch.cat(losses, dim=2)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def to_prediction(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        if y_pred.ndim == 3:\n",
    "            idx = self.quantiles.index(0.5)\n",
    "            y_pred = y_pred[..., idx]\n",
    "        return y_pred\n",
    "\n",
    "    def to_quantiles(self, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081f187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "#lr = 0.001\n",
    "hidden = 64\n",
    "atten_head = 4\n",
    "dropout = 0.1\n",
    "quantiles = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "alpha_start = 0.7\n",
    "\n",
    "\n",
    "filter = np.array([2, 1, 0]) \n",
    "\n",
    "def triangle_conv(time_series):\n",
    "    global filter\n",
    "    size = len(filter)\n",
    "    shift = size // 2\n",
    "    conv_result = np.convolve(time_series, filter, mode='same')\n",
    "    conv_result = np.roll(conv_result, shift)\n",
    "    return conv_result\n",
    "\n",
    "def inv_conv(time_series):\n",
    "    return time_series\n",
    "\n",
    "transformation_dict = {\n",
    "    'forward': triangle_conv,\n",
    "    'reverse': inv_conv, \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11e2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 24\n",
    "max_encoder_length = 24*7\n",
    "\n",
    "data = pd.read_csv('../../../DataProcessing/train_data/Long Beach_5_split.csv')\n",
    "noise = np.random.uniform(0, 1.0, size=data['Accient'].shape)\n",
    "data['Accient'] = data['Accient'] + noise\n",
    "\n",
    "#data = data[lambda x : x.time_idx <= 400]\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Accient\",\n",
    "    group_ids=[\"GeoHash\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=data.columns[4: -2].tolist(),\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"GeoHash\"], transformation=transformation_dict\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2e74a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 42.5k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | CustomLoss                      | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 608   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.7 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 23.7 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.2 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808   \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "42.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.5 K    Total params\n",
      "0.170     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c05a95c752428ab086a307d953cb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-6, patience=10, verbose=False, mode=\"min\")\n",
    "logger = TensorBoardLogger(f\"lightning_logs/test\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger=logger,\n",
    "    devices = [0]\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=1e-4,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    loss=CustomLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    output_size = 7,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
