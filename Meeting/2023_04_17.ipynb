{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066b5309",
   "metadata": {},
   "source": [
    "# 2023_04_17\n",
    "\n",
    "지금은 geohash의 `precision = 7`로 해서 데이터를 생성함  \n",
    "도시를 소도시로 잡아서 그런가 weather data와 accient data를 병합이 되는 데이터가 적음  \n",
    "`precision = 5` or `precision = 6`에 대해서 모든 데이터를 생성하고 데이터가 얼마나 생성되는지 확인  \n",
    "이때 weather data가 1시간 단위가 아니라 구간으로 되어 있어서 1시간 단위로 분리하는 작업이 따로 필요함  \n",
    "\n",
    "\n",
    "> validation code : http://202.31.200.70:8888/notebooks/NPLAB-NAS/Members/SEO/Emergency_Demand/Traffic_Accient/Preproecssing_data_all_city_validation.ipynb\n",
    "\n",
    "다음과 같이 python 코드로 해서 실행\n",
    "360시간 정도 시간이 소요됨  \n",
    "\n",
    "```python\n",
    "# 필요한 패키지 로드\n",
    "import geohash\n",
    "import folium\n",
    "import geohash\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm , tqdm_notebook\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='The frame.append method is deprecated')\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('./data/TrafficEvents_Aug16_Dec20_Publish.csv')\n",
    "\n",
    "weather_df = pd.read_csv('./data/WeatherEvents_Aug16_Dec20_Publish.csv')\n",
    "\n",
    "union_city = list(set(df['City'].unique()) & set(weather_df['City'].unique()))\n",
    "\n",
    "precision = 5\n",
    "city_merge_dfs = []\n",
    "\n",
    "for city in tqdm(union_city[1:]):\n",
    "    # Accident data\n",
    "    city_df = df[df['City'] == city]\n",
    "    city_df['StartTime(UTC)'] = pd.to_datetime(city_df['StartTime(UTC)'])\n",
    "    city_df['EndTime(UTC)'] = pd.to_datetime(city_df['EndTime(UTC)'])\n",
    "    city_df['OccTime'] = city_df['StartTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "    city_df['EndTime'] = city_df['EndTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "    city_df['GeoHash'] = city_df.apply(lambda row: geohash.encode(row['LocationLat'], row['LocationLng'], precision=precision), axis=1)\n",
    "    \n",
    "    insert_columns = ['OccTime', 'EndTime', 'GeoHash', 'Type', 'Severity', 'EventId', 'Distance(mi)', 'Description']\n",
    "    count_df = pd.DataFrame(columns=insert_columns)\n",
    "    \n",
    "    for e_id in tqdm(city_df['EventId'], desc = f'{city} Traffic'):\n",
    "        event_df = city_df[city_df['EventId'] == e_id][insert_columns]\n",
    "        dt = pd.date_range(event_df['OccTime'].iloc[0], event_df['EndTime'].iloc[0], freq='1h')\n",
    "        for d in dt:\n",
    "            count_df = count_df.append(event_df.iloc[0], ignore_index=True)\n",
    "\n",
    "    count_df = count_df[count_df['OccTime'].notnull()]\n",
    "    \n",
    "    # Weather data\n",
    "    weather_city_df = weather_df[weather_df['City'] == city]\n",
    "    weather_city_df['StartTime(UTC)'] = pd.to_datetime(weather_city_df['StartTime(UTC)'])\n",
    "    weather_city_df['EndTime(UTC)'] = pd.to_datetime(weather_city_df['EndTime(UTC)'])\n",
    "    weather_city_df['OccTime'] = weather_city_df['StartTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "    weather_city_df['EndTime'] = weather_city_df['EndTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "    weather_city_df['GeoHash'] = weather_city_df.apply(lambda row: geohash.encode(row['LocationLat'], row['LocationLng'], precision=precision), axis=1)\n",
    "    \n",
    "    weather_insert_columns = ['OccTime', 'EndTime', 'Type', 'GeoHash']\n",
    "    weather_count_df = pd.DataFrame(columns=weather_insert_columns)\n",
    "    \n",
    "    for e_id in tqdm(weather_city_df['EventId'],desc =f'{city} weather'):\n",
    "        weather_event_df = weather_city_df[weather_city_df['EventId'] == e_id][weather_insert_columns]\n",
    "        dt = pd.date_range(weather_event_df['OccTime'].iloc[0], weather_event_df['EndTime'].iloc[0], freq='1h')\n",
    "        for d in dt:\n",
    "            weather_count_df = weather_count_df.append(weather_event_df.iloc[0], ignore_index=True)\n",
    "\n",
    "    weather_count_df = weather_count_df[weather_count_df['OccTime'].notnull()]\n",
    "    \n",
    "    # Merge accident and weather data\n",
    "    result_df = pd.merge(count_df, weather_count_df, how='inner', on=['OccTime', 'GeoHash'])\n",
    "    if len(result_df) > 1:\n",
    "        result_df.to_csv(f'./result_csv/{precision}/{city}_{precision}.csv' ,index=False)\n",
    "\n",
    "```\n",
    "\n",
    "주피터 노트북에서는 15시간 정도가 소요되는걸로 나왔으나 python으로 실행시키니 360 시간정도가 소요됨    \n",
    "이는 현실적으로 하기가 불가능함  \n",
    "\n",
    "인구 데이터와 공항을 기반으로 적절한 도시 선택  필요  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0804a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
